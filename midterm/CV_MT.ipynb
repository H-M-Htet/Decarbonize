{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0488146d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85d8106",
   "metadata": {},
   "source": [
    "## Theoretical Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4363282",
   "metadata": {},
   "source": [
    "### TQ1 - [10 Points]: What are the main challenges in Computer Vision and why are they difficult to handle?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87388050",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c3d27b",
   "metadata": {},
   "source": [
    "### TQ2 - [15 Points]: Explain Properties of Linear Shift Invariant System. Also explain how we can find $h$.\n",
    "<img src=\"resources/assets/LSIS.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c1e63a",
   "metadata": {},
   "source": [
    "Your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17845afe",
   "metadata": {},
   "source": [
    "### TQ3 - [10 Points] What are the problems of fitting a line with $y = mx +c$ in Hough Transform? What is a better paramenterization and why is it better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf731d59",
   "metadata": {},
   "source": [
    "Your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f044bd",
   "metadata": {},
   "source": [
    "### TQ4 - [20 Points]: What are the main steps in the SIFT algorimth. Clearly explain how `Scale-space extrema detection` works. And discuss why SIFT is invariant to scale and rotation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eae3483",
   "metadata": {},
   "source": [
    "Your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa1d736",
   "metadata": {},
   "source": [
    "### TQ5 - [10 Points] Compute Intrinsic Camera Matrix for Samsung S25 Ultra Camera\n",
    "<img src=\"resources/assets/Galaxy.jpeg\" width=640 height=360>\n",
    "\n",
    "\n",
    "- Resolution: 50 MP, `9,184 x 5,166`\n",
    "- Wide-Angle Lens Horizontal Field of View: `84 degree`\n",
    "- Focal Length: `24 mm`\n",
    "\n",
    "Assume that the sensor is perfectly centered along the optical axis, and that it has the same vertical and horizontal photoreceptor spacing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e7aa2",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c04cfc",
   "metadata": {},
   "source": [
    "### TQ6 - [15 Points]: Linear classifier can be interpreted in different viewpoints. Briefly explain each viewpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f4061",
   "metadata": {},
   "source": [
    "Your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe81654",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5fbc27",
   "metadata": {},
   "source": [
    "## Implementation Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68162d66",
   "metadata": {},
   "source": [
    "### IQ1 - [15 Points]: Implement a histogram equalizaton using CLAHE technique with clipLimit = 2, 4and 8. \n",
    "Use the image in `ques_asset/IQ1`\n",
    "- Plot the orignal image and its histogram\n",
    "- Plot CLAHE image and its histogram \n",
    "- Analyze the difference you notice from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da8e77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55ae091",
   "metadata": {},
   "source": [
    "### IQ2 - Image Filters\n",
    "\n",
    "Use the image in `ques_assets/IQ2` to answer IQ2.1 - 2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceae3aa",
   "metadata": {},
   "source": [
    "#### IQ2.1 - [5 Points] Write a python code to apply the following filters to a given image,\n",
    "- Gaussian filter with `kernel size = 9` and `sigmaX = sigmaY = 50`\n",
    "- Bilateral filter with `kernel size = 9` and  `spatial and color sigma = 90`\n",
    "- Show the result images side-by-side\n",
    "\n",
    "Analyze the differences in the results. Explain why the bilateral filter is better at preserving edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4843d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7cf7c6",
   "metadata": {},
   "source": [
    "#### IQ2.2 - [15 Points]: Write a python code to apply a bilateral filter with the following spatial and color (Brightness) sigma values and show the results\n",
    "\n",
    "Spatial Sigma | Color Sigma\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <th>Spatial Sigma</th>\n",
    "    <th>Color Sigma</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <td>9</td>\n",
    "    <td>9</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <td>9</td>\n",
    "    <td>75</td>   \n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <td>9</td>\n",
    "    <td>500</td>   \n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <td>75</td>\n",
    "    <td>9</td>   \n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <td>500</td>\n",
    "    <td>9</td>   \n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Note that `d=9` for all sigma.\n",
    "\n",
    "Explain how the choice of sigma values affects the filtering results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe4d20",
   "metadata": {},
   "source": [
    "### IQ3 - SIFT and Image Alignment\n",
    "Using `SIFT`detector, detect `feature points` and calculate `descriptors`. Then `match` correnspondences between two given images in `ques_assets/IQ3`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7d946d",
   "metadata": {},
   "source": [
    "#### IQ3.1 - [5 Points]: Draw keypoints for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d9556",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecce6d6",
   "metadata": {},
   "source": [
    "#### IQ3.2 - [5 Points]: Draw the matched keypoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363313a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa1985",
   "metadata": {},
   "source": [
    "#### IQ3.3 - [5 Points]: Plot the `most` similar keypoint pair using their `descriptors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1569613",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c25f821",
   "metadata": {},
   "source": [
    "#### IQ3.4 - [5 Points]: Change a parameter of SIFT_create() function to increase the number of images in a scale-space to =`5`, and find `keypoints` and `descriptors` in `book_scene.jpeg` only. Analyze how the result (keypoints) changes in response to this parameter change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb3c09",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ce1587",
   "metadata": {},
   "source": [
    "### IQ4 - [25 Points]: Implememt and compare a `Linear Classifier` for image classification using `Multiclass SVM Loss` and `Cross Entropy loss`.\n",
    "Your implementation should\n",
    "- Use `pytorch`\n",
    "- Use `CIFAR10`  as a dataset\n",
    "- Use `learning_rate = 0.1`\n",
    "- Train for `epoch=30` and `batch_size` of your choice.\n",
    "\n",
    "Report classification accuracy for each loss, and discuss which loss function gives better performance and why.\n",
    "\n",
    "`Hint`:\n",
    "- In PyTorch, the multiclass SVM loss is typically implemented using the `MultiMarginLoss` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4a302",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
