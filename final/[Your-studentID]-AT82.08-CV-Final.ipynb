{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c05611",
   "metadata": {},
   "source": [
    "# AT82.08 Computer Vision Midterm Exam\n",
    "\n",
    "Date & Time: Nov 29, 2025. From 0900 - 1200\n",
    "\n",
    "Exam Duration: 3 Hours\n",
    "\n",
    "Total Score: 100 Points = TQ(50 points) + IQ (50 points)\n",
    "\n",
    "## How to submit\n",
    "1. Zip the downloaded folder, and it should contain\n",
    "- jupyter notebook\n",
    "- any images you added to the notebook should be in `assets/`.\n",
    "\n",
    "*If the zip file is larger than 8 MB, you can split them into two zip files, one contains jupyter notebook, and other contains assets.*\n",
    "\n",
    "2. Submit the zip on `TEAL`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ebb449",
   "metadata": {},
   "source": [
    "# Theoretical Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a85cc",
   "metadata": {},
   "source": [
    "## TQ1-[5 Points] : Stochastic Gradient Descent\n",
    "\n",
    "Given the stochastic Gradient Descent\n",
    "\n",
    "> **Algorithm**\n",
    "> 1. Initialize weights randomly $\\mathcal{N}(0,\\sigma^2)$\n",
    "> 2. Loop until convergence:\n",
    ">   * Pick single data point *i*\n",
    ">   * Compute gradient $\\frac{\\partial J_i(W)}{\\partial W}$\n",
    ">   * Update weights $W \\larr W - \\eta\\frac{\\partial J(W)}{\\partial W}$ \n",
    "> 3. Return weights\n",
    "\n",
    "**What are advantages and disadvantages of this method? How can we address the drawback of this method?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166ce8a",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a9be3f",
   "metadata": {},
   "source": [
    "## TQ2-[10 Points] : What are the purpose and properties of activation function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b2abe",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836636b",
   "metadata": {},
   "source": [
    "## TQ3-[5 Points] : What is the effective receptive field size of each neuron in layer `L=5` with `3x3` kernel size in each layer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9198df1f",
   "metadata": {},
   "source": [
    "*Please show your solution, not just the answer*\n",
    "\n",
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7719e",
   "metadata": {},
   "source": [
    "## TQ4-[10 Points] : We've explored the evolution of the `R-CNN family`, encompassing `R-CNN`, `Fast R-CNN`, and `Faster R-CNN`. Analyze the key differences between these models, identifying their respective limitations and the specific challenges they were developed to overcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb272fd6",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0bff6",
   "metadata": {},
   "source": [
    "## TQ5-[10 Points] : What is Object Tracking? Why do we need tracking? What are elements of tracking? Briefly explain each element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed6b9c7",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a65526",
   "metadata": {},
   "source": [
    "## TQ6-[10 Points] : What are 3D Representations that we have discussed in this course? Briefly explain each representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfa197e",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c145341b",
   "metadata": {},
   "source": [
    "# Implementation Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d1bdd9",
   "metadata": {},
   "source": [
    "## IQ1-[15 Points] : Mean Shift\n",
    "As previously discussed, Mean Shift segmentation leverages Euclidean distance to cluster pixels in a feature space defined by pixel attributes. While we have utilized `RGB` color information as features, incorporating additional spatial information may enhance segmentation performance. By augmenting the feature space to include pixel coordinates `(X,Y)`, we can apply Mean Shift to this expanded representation.\n",
    "\n",
    "\n",
    "#### Implement Mean Shift segmentation using the `RGBXY` space of the given image (`assets/labradors.jpg`).\n",
    "- How does the performance compare to using only the RGB color space?\n",
    "- Show the center of clusters, how many clusters are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f17e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a980224",
   "metadata": {},
   "source": [
    "## IQ2: GAN\n",
    "In lecture 12, we learnt and implemented GAN in which the generator and discriminator were constructed with only linear layers, and trained using MNIST dataset. We observed that the quality of genereted images was not good, and needed further improvement.\n",
    "\n",
    "[DCGAN](https://arxiv.org/pdf/1511.06434.pdf) is an extension of the GAN, in which it explicitly uses `convolutional` and `convTransposed` layers in the discriminator and generator, respectively. In other words, DCGAN replaces linear layers in GAN with `conv.` layers in the discriminator, and `convTranspose` layers in the generator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2352cddd",
   "metadata": {},
   "source": [
    "### IQ2.1-[25 Points] : Implement DCGAN\n",
    "\n",
    "Use the following guideline to `Implement DCGAN model`:\n",
    "- `4 conv. layers` in the `discrimimator`.\n",
    "- `4 convTranspose layers` in the `generator`.\n",
    "- latent vector `z = 100` and being sample from a `normal` distribution\n",
    "- Use `batchnorm` in both the generator and the discriminator.\n",
    "- Use `ReLU` as activation function in generator for all layers except for the output, which uses `Tanh`.\n",
    "- Use `LeakyReLU` as activation function in the discriminator for all layers.\n",
    "\n",
    "\n",
    "Train the model\n",
    "- `MNIST` dataset\n",
    "- `25` epochs\n",
    "- batch size of `128`\n",
    "\n",
    "**`Report the following`**\n",
    "- Plot both generator and discriminator `losses`.\n",
    "- Show the visualization of the generated images of `every 5 epochs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b24fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08582f26",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a306cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "latent_z = 100\n",
    "\n",
    "# Hyperparameters\n",
    "glr = 2e-4\n",
    "dlr= 2e-4\n",
    "\n",
    "NUM_EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "logging_interval = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6010e13",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6beea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict = {'train_generator_loss_per_batch': [],\n",
    "              'train_discriminator_loss_per_batch': [],\n",
    "              'train_discriminator_real_acc_per_batch': [],\n",
    "              'train_discriminator_fake_acc_per_batch': [],\n",
    "              'images_from_noise_per_epoch': []}\n",
    "\n",
    "# Batch of latent (noise) vectors for\n",
    "# evaluating / visualizing the training progress\n",
    "# of the generator\n",
    "# -----Your code here ------\n",
    "fixed_z = # Your code here\n",
    "# --------------------------\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "  gen.train()\n",
    "  dis.train()\n",
    "  for batch_idx, (features, _) in enumerate(train_loader):\n",
    "\n",
    "    batch_size = features.size(0)\n",
    "\n",
    "    # real images\n",
    "    real_images = features.to(device)\n",
    "    real_labels = torch.ones(batch_size, device=device) # real label = 1\n",
    "\n",
    "    # generated (fake) images\n",
    "\n",
    "    # -----Your code here ------\n",
    "    z = # Your code here\n",
    "    # --------------------------\n",
    "\n",
    "    fake_images = gen(z)\n",
    "    fake_labels = torch.zeros(batch_size, device=device) # fake label = 0\n",
    "    flipped_fake_labels = real_labels # here, fake label = 1\n",
    "    flipped_fake_labels.to(device)\n",
    "\n",
    "\n",
    "    # --------------------------\n",
    "    # Train Discriminator\n",
    "    # --------------------------\n",
    "\n",
    "    optimizer_D.zero_grad()\n",
    "\n",
    "    # get discriminator loss on real images\n",
    "    discr_pred_real = dis(real_images).view(-1) # Nx1 -> N\n",
    "    real_loss = adversarial_loss(discr_pred_real, real_labels)\n",
    "\n",
    "    # get discriminator loss on fake images\n",
    "    discr_pred_fake = dis(fake_images.detach()).view(-1)\n",
    "    fake_loss = adversarial_loss(discr_pred_fake, fake_labels)\n",
    "\n",
    "    # combined loss\n",
    "    discr_loss = 0.5*(real_loss + fake_loss)\n",
    "\n",
    "    discr_loss.backward()\n",
    "    optimizer_D.step()\n",
    "\n",
    "    # --------------------------\n",
    "    # Train Generator\n",
    "    # --------------------------\n",
    "\n",
    "    optimizer_G.zero_grad()\n",
    "\n",
    "    # get discriminator loss on fake images with flipped labels\n",
    "    discr_pred_fake = dis(fake_images).view(-1)\n",
    "    gener_loss = adversarial_loss(discr_pred_fake, flipped_fake_labels)\n",
    "    gener_loss.backward()\n",
    "\n",
    "    optimizer_G.step()\n",
    "\n",
    "    # --------------------------\n",
    "    # Logging\n",
    "    # --------------------------\n",
    "    log_dict['train_generator_loss_per_batch'].append(gener_loss.item())\n",
    "    log_dict['train_discriminator_loss_per_batch'].append(discr_loss.item())\n",
    "\n",
    "    predicted_labels_real = torch.where(discr_pred_real.detach() > 0., 1., 0.)\n",
    "    predicted_labels_fake = torch.where(discr_pred_fake.detach() > 0., 1., 0.)\n",
    "\n",
    "    acc_real = (predicted_labels_real == real_labels).float().mean()*100.\n",
    "    acc_fake = (predicted_labels_fake == fake_labels).float().mean()*100.\n",
    "\n",
    "    log_dict['train_discriminator_real_acc_per_batch'].append(acc_real.item())\n",
    "    log_dict['train_discriminator_fake_acc_per_batch'].append(acc_fake.item())\n",
    "\n",
    "    if not batch_idx % logging_interval:\n",
    "      print('Epoch: %03d/%03d | Batch %03d/%03d | Gen/Dis Loss: %.4f/%.4f'\n",
    "              % (epoch+1, NUM_EPOCHS, batch_idx,\n",
    "                len(train_loader), gener_loss.item(), discr_loss.item()))\n",
    "\n",
    "  ### Save images for evaluation\n",
    "  with torch.no_grad():\n",
    "    fake_images = gen(fixed_z).detach().cpu()\n",
    "    log_dict['images_from_noise_per_epoch'].append(make_grid(fake_images,\n",
    "                                                              padding=2,\n",
    "                                                              normalize=True))\n",
    "  print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "\n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b338c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca89208",
   "metadata": {},
   "source": [
    "#### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### VISUALIZATION\n",
    "##########################\n",
    "\n",
    "for i in range(0, NUM_EPOCHS, 5):\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.axis('off')\n",
    "  plt.title(f'Generated images at epoch {i}')\n",
    "  plt.imshow(np.transpose(log_dict['images_from_noise_per_epoch'][i], (1, 2, 0)))\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis('off')\n",
    "plt.title(f'Generated images after last epoch')\n",
    "plt.imshow(np.transpose(log_dict['images_from_noise_per_epoch'][-1], (1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7177ce4",
   "metadata": {},
   "source": [
    "### IQ2.2-[10 Points]: Qualitative Comparison\n",
    "\n",
    "\n",
    "Recall from our GAN lab session, we implemented and trained GAN on MNIST dataset.\n",
    "\n",
    "Conduct a comparative analysis of the image outputs generated by `GAN` and `DCGAN` models at the `25th` epoch. Determine which model produces better quality images and discuss the underlying reasons for its superior performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8802e4ca",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b6367d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
